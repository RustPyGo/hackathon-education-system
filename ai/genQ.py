import os
import json
import requests
from pathlib import Path
from dotenv import load_dotenv
import hashlib
from datetime import datetime
import subprocess
import sys

# Import cho RAG
try:
    from sentence_transformers import SentenceTransformer
    import numpy as np
    from sklearn.metrics.pairwise import cosine_similarity
    import pickle
except ImportError:
    print("âŒ Thiáº¿u má»™t sá»‘ thÆ° viá»‡n cáº§n thiáº¿t. Äang cÃ i Ä‘áº·t...")
    subprocess.check_call([sys.executable, "-m", "pip", "install", "sentence-transformers", "scikit-learn", "numpy"])
    from sentence_transformers import SentenceTransformer
    import numpy as np
    from sklearn.metrics.pairwise import cosine_similarity
    import pickle

# Load environment variables
load_dotenv()

class PDFQuestionGenerator:
    def __init__(self):
        """Khá»Ÿi táº¡o há»‡ thá»‘ng táº¡o cÃ¢u há»i tá»« PDF"""
        self.openai_api_key = os.getenv('OPENAI_API_KEY')
        if not self.openai_api_key:
            print("âŒ Lá»—i: KhÃ´ng tÃ¬m tháº¥y OPENAI_API_KEY trong file .env")
            sys.exit(1)
        
        # Khá»Ÿi táº¡o model embedding
        print("ğŸ”„ Äang táº£i mÃ´ hÃ¬nh embedding...")
        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
        
        # Biáº¿n lÆ°u trá»¯
        self.pdf_content = ""
        self.chunks = []
        self.embeddings = []
        self.document_summary = ""
        
        print("âœ… Há»‡ thá»‘ng táº¡o cÃ¢u há»i Ä‘Ã£ sáºµn sÃ ng!")
    
    def convert_pdf_to_text(self, pdf_path):
        """Chuyá»ƒn Ä‘á»•i PDF sang text sá»­ dá»¥ng pdfToText.py"""
        try:
            print(f"ğŸ“„ Äang chuyá»ƒn Ä‘á»•i PDF: {pdf_path}")
            
            # Import pdfToText module
            import importlib.util
            spec = importlib.util.spec_from_file_location("pdfToText", "pdfToText.py")
            pdf_module = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(pdf_module)
            
            # Táº¡o file output táº¡m thá»i
            temp_output = f"temp_gen_pdf_{hashlib.md5(pdf_path.encode()).hexdigest()[:8]}.txt"
            
            # Chuyá»ƒn Ä‘á»•i PDF
            success = pdf_module.pdf_to_text(pdf_path, temp_output)
            
            if success and os.path.exists(temp_output):
                with open(temp_output, 'r', encoding='utf-8') as f:
                    self.pdf_content = f.read()
                
                # XÃ³a file táº¡m
                os.remove(temp_output)
                
                # Kiá»ƒm tra ná»™i dung
                if len(self.pdf_content.strip()) == 0:
                    print("âŒ PDF khÃ´ng chá»©a text cÃ³ thá»ƒ Ä‘á»c Ä‘Æ°á»£c")
                    return False
                
                # Thá»‘ng kÃª
                error_pages = self.pdf_content.count("[Lá»–I TRÃCH XUáº¤T:")
                empty_pages = self.pdf_content.count("[TRANG TRá»NG")
                
                print(f"âœ… Chuyá»ƒn Ä‘á»•i PDF thÃ nh cÃ´ng!")
                print(f"ğŸ“Š Thá»‘ng kÃª ná»™i dung:")
                print(f"   - Äá»™ dÃ i: {len(self.pdf_content):,} kÃ½ tá»±")
                if error_pages > 0:
                    print(f"   - âš ï¸ Trang lá»—i: {error_pages}")
                if empty_pages > 0:
                    print(f"   - ğŸ“ Trang trá»‘ng: {empty_pages}")
                
                return True
            else:
                print("âŒ Lá»—i chuyá»ƒn Ä‘á»•i PDF")
                return False
                
        except Exception as e:
            print(f"âŒ Lá»—i: {str(e)}")
            return False
    
    def clean_text(self, text):
        """LÃ m sáº¡ch text vÃ  loáº¡i bá» pháº§n khÃ´ng cáº§n thiáº¿t"""
        import re
        
        # Loáº¡i bá» header trang
        text = re.sub(r'={50}\nTRANG \d+\n={50}', '', text)
        
        # Loáº¡i bá» thÃ´ng bÃ¡o lá»—i
        text = re.sub(r'\[Lá»–I TRÃCH XUáº¤T:.*?\]', '', text)
        text = re.sub(r'\[TRANG TRá»NG.*?\]', '', text)
        
        # Loáº¡i bá» dÃ²ng trá»‘ng liÃªn tiáº¿p
        text = re.sub(r'\n\s*\n\s*\n', '\n\n', text)
        
        # Loáº¡i bá» khoáº£ng tráº¯ng thá»«a
        text = re.sub(r' +', ' ', text)
        
        return text.strip()
    
    def create_chunks(self, text, chunk_size=1000, overlap=100):
        """Chia text thÃ nh chunks lá»›n hÆ¡n Ä‘á»ƒ phÃ¢n tÃ­ch toÃ n diá»‡n"""
        cleaned_text = self.clean_text(text)
        words = cleaned_text.split()
        chunks = []
        
        for i in range(0, len(words), chunk_size - overlap):
            chunk = ' '.join(words[i:i + chunk_size])
            if len(chunk.strip()) > 100:  # Chunk tá»‘i thiá»ƒu 100 kÃ½ tá»±
                chunks.append(chunk.strip())
        
        print(f"ğŸ“š ÄÃ£ táº¡o {len(chunks)} chunks Ä‘á»ƒ phÃ¢n tÃ­ch")
        return chunks
    
    def create_embeddings(self):
        """Táº¡o embeddings cho cÃ¡c chunks"""
        print("ğŸ”„ Äang táº¡o chunks vÃ  embeddings...")
        
        # Táº¡o chunks
        self.chunks = self.create_chunks(self.pdf_content)
        
        if not self.chunks:
            print("âŒ KhÃ´ng cÃ³ chunks há»£p lá»‡")
            return False
        
        # Táº¡o embeddings
        self.embeddings = self.embedding_model.encode(self.chunks)
        
        print(f"âœ… ÄÃ£ táº¡o embeddings cho {len(self.chunks)} chunks")
        return True
    
    def call_openai_api(self, prompt, max_tokens=2000):
        """Gá»i OpenAI API vá»›i error handling tá»‘t hÆ¡n"""
        try:
            # Kiá»ƒm tra Ä‘á»™ dÃ i prompt
            if len(prompt) > 12000:  # Giá»›i háº¡n an toÃ n
                print(f"âš ï¸ Prompt quÃ¡ dÃ i ({len(prompt)} chars), cáº¯t ngáº¯n...")
                prompt = prompt[:12000] + "..."
            
            url = "https://api.openai.com/v1/chat/completions"
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {self.openai_api_key}"
            }
            
            data = {
                "model": "gpt-3.5-turbo",
                "messages": [
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                "max_tokens": min(max_tokens, 2000),  # Giá»›i háº¡n max_tokens
                "temperature": 0.7
            }
            
            response = requests.post(url, headers=headers, json=data, timeout=30)
            
            # Kiá»ƒm tra status code
            if response.status_code != 200:
                print(f"âŒ OpenAI API error: {response.status_code}")
                print(f"Response: {response.text}")
                return None
                
            result = response.json()
            
            if 'choices' in result and len(result['choices']) > 0:
                return result['choices'][0]['message']['content']
            else:
                print(f"âŒ Lá»—i API response: {result}")
                return None
                
        except Exception as e:
            print(f"âŒ Lá»—i gá»i API: {str(e)}")
            return None
    
    def generate_document_summary(self):
        """Táº¡o tÃ³m táº¯t tá»•ng quan tÃ i liá»‡u"""
        print("ğŸ“ Äang táº¡o tÃ³m táº¯t tÃ i liá»‡u...")
        
        # Láº¥y ná»™i dung quan trá»ng (giá»›i háº¡n Ä‘á»™ dÃ i)
        important_content = ""
        if len(self.chunks) >= 2:
            important_content = self.chunks[0][:1500] + "\n\n" + self.chunks[1][:1500]
        elif len(self.chunks) == 1:
            important_content = self.chunks[0][:2000]
        else:
            important_content = "Ná»™i dung tÃ i liá»‡u ngáº¯n"
        
        prompt = f"""TÃ³m táº¯t ngáº¯n gá»n ná»™i dung sau trong 100 tá»«:

{important_content}

TÃ³m táº¯t chá»§ Ä‘á» chÃ­nh vÃ  khÃ¡i niá»‡m quan trá»ng:"""
        
        summary = self.call_openai_api(prompt, max_tokens=300)
        if summary:
            self.document_summary = summary
            print("âœ… ÄÃ£ táº¡o tÃ³m táº¯t tÃ i liá»‡u")
        else:
            self.document_summary = "TÃ i liá»‡u há»c táº­p vá»›i cÃ¡c khÃ¡i niá»‡m vÃ  kiáº¿n thá»©c cáº§n thiáº¿t."
            print("âš ï¸ Sá»­ dá»¥ng tÃ³m táº¯t máº·c Ä‘á»‹nh")
        
        return self.document_summary
    
    def get_relevant_content_for_topic(self, topic, num_chunks=3):
        """Láº¥y ná»™i dung liÃªn quan cho má»™t chá»§ Ä‘á» cá»¥ thá»ƒ"""
        if not self.chunks or len(self.embeddings) == 0:
            return ""
        
        # Táº¡o embedding cho topic
        topic_embedding = self.embedding_model.encode([topic])
        
        # TÃ­nh similarity
        similarities = cosine_similarity(topic_embedding, self.embeddings)[0]
        
        # Láº¥y top chunks
        top_indices = np.argsort(similarities)[::-1][:num_chunks]
        
        relevant_content = []
        for idx in top_indices:
            relevant_content.append(self.chunks[idx])
        
        return "\n\n".join(relevant_content)
    
    def generate_questions(self, num_questions=5):
        """Táº¡o cÃ¢u há»i tráº¯c nghiá»‡m tá»« tÃ i liá»‡u vá»›i batch processing"""
        print(f"ğŸ¤– Äang táº¡o {num_questions} cÃ¢u há»i tráº¯c nghiá»‡m...")
        
        # Táº¡o tÃ³m táº¯t náº¿u chÆ°a cÃ³
        if not self.document_summary:
            self.generate_document_summary()
        
        # Chia thÃ nh batch Ä‘á»ƒ trÃ¡nh giá»›i háº¡n token
        batch_size = 8  # Sá»‘ cÃ¢u há»i tá»‘i Ä‘a má»—i batch
        all_questions = {"questions": []}
        
        if num_questions <= batch_size:
            # Náº¿u sá»‘ cÃ¢u há»i nhá», táº¡o má»™t láº§n
            return self.generate_questions_batch(num_questions, 1)
        
        # Chia thÃ nh nhiá»u batch
        total_batches = (num_questions + batch_size - 1) // batch_size
        print(f"ğŸ“¦ Chia thÃ nh {total_batches} batch (tá»‘i Ä‘a {batch_size} cÃ¢u/batch)")
        
        question_id = 1
        for batch_num in range(total_batches):
            remaining_questions = num_questions - len(all_questions["questions"])
            current_batch_size = min(batch_size, remaining_questions)
            
            if current_batch_size <= 0:
                break
                
            print(f"ğŸ”„ Äang xá»­ lÃ½ batch {batch_num + 1}/{total_batches} ({current_batch_size} cÃ¢u)...")
            
            # Táº¡o cÃ¢u há»i cho batch nÃ y
            batch_questions = self.generate_questions_batch(current_batch_size, question_id)
            
            if batch_questions and batch_questions.get("questions"):
                # Cáº­p nháº­t ID cho cÃ¢u há»i
                for q in batch_questions["questions"]:
                    q["id"] = question_id
                    question_id += 1
                    all_questions["questions"].append(q)
                
                print(f"âœ… HoÃ n thÃ nh batch {batch_num + 1} - {len(batch_questions['questions'])} cÃ¢u")
            else:
                print(f"âš ï¸ Batch {batch_num + 1} tháº¥t báº¡i, thá»­ láº¡i...")
                # Thá»­ láº¡i vá»›i format Ä‘Æ¡n giáº£n
                batch_questions = self.generate_questions_simple_format_batch(current_batch_size, question_id)
                if batch_questions and batch_questions.get("questions"):
                    for q in batch_questions["questions"]:
                        all_questions["questions"].append(q)
                        question_id += 1
        
        print(f"ğŸ¯ Tá»•ng cá»™ng Ä‘Ã£ táº¡o {len(all_questions['questions'])}/{num_questions} cÃ¢u há»i")
        return all_questions
    
    def get_concise_content(self, num_questions):
        """Láº¥y ná»™i dung ngáº¯n gá»n cho táº¡o cÃ¢u há»i"""
        if not self.chunks:
            return "Ná»™i dung tÃ i liá»‡u cáº§n thiáº¿t cho cÃ¢u há»i."
        
        # Láº¥y chunks Ä‘áº§u vÃ  giá»¯a, giá»›i háº¡n Ä‘á»™ dÃ i
        content_parts = []
        
        if len(self.chunks) >= 2:
            # Chunk Ä‘áº§u
            content_parts.append(self.chunks[0][:800])
            # Chunk giá»¯a
            mid_idx = len(self.chunks) // 2
            content_parts.append(self.chunks[mid_idx][:800])
        else:
            content_parts.append(self.chunks[0][:1200])
        
        return "\n\n".join(content_parts)

    def generate_questions_batch(self, batch_size, start_id):
        """Táº¡o má»™t batch cÃ¢u há»i vá»›i prompt tá»‘i Æ°u"""
        # Láº¥y ná»™i dung ngáº¯n gá»n
        content_summary = self.get_concise_content(batch_size)
        
        prompt = f"""Táº¡o {batch_size} cÃ¢u há»i tráº¯c nghiá»‡m tá»« ná»™i dung sau:

KIáº¾N THá»¨C:
{content_summary}

YÃŠU Cáº¦U:
- {batch_size} cÃ¢u há»i, má»—i cÃ¢u 4 Ä‘Ã¡p Ã¡n A,B,C,D
- Kiá»ƒm tra hiá»ƒu biáº¿t, khÃ´ng há»i "tÃ i liá»‡u nÃ³i gÃ¬"
- ÄÃ¡p Ã¡n Ä‘Ãºng duy nháº¥t, sai há»£p lÃ½

FORMAT JSON:
{{
  "questions": [
    {{
      "question": "CÃ¢u há»i...",
      "type": "multiple_choice",
      "hint": "Gá»£i Ã½ ngáº¯n",
      "correct_answer": "A",
      "options": [
        {{"answer": "A", "content": "ÄÃ¡p Ã¡n A", "reason": "ÄÃºng vÃ¬..."}},
        {{"answer": "B", "content": "ÄÃ¡p Ã¡n B", "reason": "Sai vÃ¬..."}},
        {{"answer": "C", "content": "ÄÃ¡p Ã¡n C", "reason": "Sai vÃ¬..."}},
        {{"answer": "D", "content": "ÄÃ¡p Ã¡n D", "reason": "Sai vÃ¬..."}}
      ]
    }}
  ]
}}

Chá»‰ tráº£ vá» JSON, khÃ´ng giáº£i thÃ­ch thÃªm:"""
        {{"answer": "B", "content": "ÄÃ¡p Ã¡n B", "reason": "Sai vÃ¬..."}},
        {{"answer": "C", "content": "ÄÃ¡p Ã¡n C", "reason": "Sai vÃ¬..."}},
        {{"answer": "D", "content": "ÄÃ¡p Ã¡n D", "reason": "Sai vÃ¬..."}}
      ]
    }}
  ]
}}

Chá»‰ tráº£ vá» JSON, khÃ´ng giáº£i thÃ­ch thÃªm:"""

ğŸ¨ MáºªU CÃ‚U Há»I Tá»T:
"Khi Ã¡p dá»¥ng phÆ°Æ¡ng phÃ¡p X Ä‘á»ƒ giáº£i quyáº¿t váº¥n Ä‘á» Y, bÆ°á»›c Ä‘áº§u tiÃªn quan trá»ng nháº¥t lÃ  gÃ¬?"
A) PhÃ¢n tÃ­ch nguyÃªn nhÃ¢n gá»‘c rá»…
B) Thu tháº­p thÃ´ng tin ban Ä‘áº§u  
C) Äá» xuáº¥t giáº£i phÃ¡p ngay láº­p tá»©c
D) ÄÃ¡nh giÃ¡ tÃ¡c Ä‘á»™ng cÃ³ thá»ƒ xáº£y ra

ğŸ“‹ FORMAT JSON TRáº¢ Vá»€:
{{
  "questions": [
    {{
      "id": {start_id},
      "question": "CÃ¢u há»i kiá»ƒm tra kiáº¿n thá»©c (KHÃ”NG há»i vá» tÃ i liá»‡u)?",
      "options": {{
        "A": "Lá»±a chá»n A",
        "B": "Lá»±a chá»n B", 
        "C": "Lá»±a chá»n C",
        "D": "Lá»±a chá»n D"
      }},
      "correct_answer": "B",
      "hint": "Gá»£i Ã½ ngáº¯n gá»n giÃºp nhá»› láº¡i kiáº¿n thá»©c",
      "explanation": "Giáº£i thÃ­ch chi tiáº¿t dá»±a trÃªn kiáº¿n thá»©c Ä‘Ã£ há»c",
      "difficulty": "easy|medium|hard",
      "topic": "Chá»§ Ä‘á» kiáº¿n thá»©c liÃªn quan"
    }}
  ]
}}

ğŸš€ Báº®T Äáº¦U Táº O {batch_size} CÃ‚U Há»I Ã”N Táº¬P:
"""
        
        result = self.call_openai_api(prompt, max_tokens=2500)
        
        try:
            questions_data = json.loads(result)
            return questions_data
        except json.JSONDecodeError:
            print("âš ï¸ Lá»—i parse JSON trong batch")
            return None
    
    def generate_questions_simple_format_batch(self, batch_size, start_id):
        """Táº¡o batch cÃ¢u há»i vá»›i format Ä‘Æ¡n giáº£n"""
        questions = {"questions": []}
        
        for i in range(batch_size):
            current_id = start_id + i
            
            # Láº¥y ná»™i dung liÃªn quan cho cÃ¢u há»i
            topics = ["khÃ¡i niá»‡m chÃ­nh", "Ä‘á»‹nh nghÄ©a", "á»©ng dá»¥ng", "vÃ­ dá»¥", "phÆ°Æ¡ng phÃ¡p", "Ä‘áº·c Ä‘iá»ƒm", "nguyÃªn lÃ½", "quy trÃ¬nh"]
            topic = topics[i % len(topics)]
            
            relevant_content = self.get_relevant_content_for_topic(topic, 2)
            
            prompt = f"""
Dá»±a trÃªn ná»™i dung sau, táº¡o 1 cÃ¢u há»i tráº¯c nghiá»‡m cháº¥t lÆ°á»£ng cao:

Ná»˜I DUNG:
{relevant_content[:1500]}

Tráº£ vá» Ä‘á»‹nh dáº¡ng:
QUESTION: [cÃ¢u há»i rÃµ rÃ ng vÃ  cá»¥ thá»ƒ]
A: [lá»±a chá»n A]
B: [lá»±a chá»n B]
C: [lá»±a chá»n C] 
D: [lá»±a chá»n D]
ANSWER: [A/B/C/D]
HINT: [gá»£i Ã½ há»¯u Ã­ch]
EXPLANATION: [lÃ½ do táº¡i sao Ä‘Ã¡p Ã¡n nÃ y Ä‘Ãºng]
"""
            
            result = self.call_openai_api(prompt, max_tokens=800)
            
            # Parse káº¿t quáº£
            question_data = self.parse_simple_question(result, current_id)
            if question_data:
                questions["questions"].append(question_data)
            else:
                print(f"âš ï¸ KhÃ´ng thá»ƒ parse cÃ¢u há»i {current_id}")
        
        return questions

    def get_diverse_content_for_questions(self, num_questions):
        """Láº¥y ná»™i dung Ä‘a dáº¡ng tá»« cÃ¡c pháº§n khÃ¡c nhau cá»§a tÃ i liá»‡u"""
        if not self.chunks:
            return self.clean_text(self.pdf_content)[:3000]
        
        # Chia chunks thÃ nh cÃ¡c nhÃ³m
        total_chunks = len(self.chunks)
        
        # Äáº£m báº£o láº¥y Ä‘á»§ ná»™i dung Ä‘a dáº¡ng
        if total_chunks <= num_questions:
            # Náº¿u Ã­t chunks, láº¥y táº¥t cáº£
            selected_content = self.chunks
        else:
            # Chia Ä‘á»u chunks Ä‘á»ƒ láº¥y ná»™i dung tá»« cÃ¡c pháº§n khÃ¡c nhau
            step = total_chunks // num_questions
            selected_content = []
            for i in range(0, total_chunks, max(1, step)):
                if len(selected_content) < num_questions and i < total_chunks:
                    selected_content.append(self.chunks[i])
        
        return "\n\n".join(selected_content)
    
    def generate_questions_simple_format(self, num_questions=5):
        """Táº¡o cÃ¢u há»i vá»›i format Ä‘Æ¡n giáº£n hÆ¡n"""
        questions = {"questions": []}
        
        for i in range(num_questions):
            # Láº¥y ná»™i dung liÃªn quan cho cÃ¢u há»i
            topics = ["khÃ¡i niá»‡m chÃ­nh", "Ä‘á»‹nh nghÄ©a", "á»©ng dá»¥ng", "vÃ­ dá»¥", "phÆ°Æ¡ng phÃ¡p"]
            topic = topics[i % len(topics)]
            
            relevant_content = self.get_relevant_content_for_topic(topic, 2)
            
            prompt = f"""
Dá»±a trÃªn ná»™i dung sau, táº¡o 1 cÃ¢u há»i tráº¯c nghiá»‡m:

Ná»˜I DUNG:
{relevant_content[:1500]}

Tráº£ vá» Ä‘á»‹nh dáº¡ng:
QUESTION: [cÃ¢u há»i]
A: [lá»±a chá»n A]
B: [lá»±a chá»n B]
C: [lá»±a chá»n C] 
D: [lá»±a chá»n D]
ANSWER: [A/B/C/D]
HINT: [gá»£i Ã½]
EXPLANATION: [lÃ½ do]
"""
            
            result = self.call_openai_api(prompt, max_tokens=800)
            
            # Parse káº¿t quáº£
            question_data = self.parse_simple_question(result, i + 1)
            if question_data:
                questions["questions"].append(question_data)
        
        return questions
    
    def parse_simple_question(self, text, question_id):
        """Parse cÃ¢u há»i tá»« format Ä‘Æ¡n giáº£n"""
        try:
            lines = text.strip().split('\n')
            question_data = {"id": question_id, "options": {}}
            
            for line in lines:
                line = line.strip()
                if line.startswith('QUESTION:'):
                    question_data["question"] = line.replace('QUESTION:', '').strip()
                elif line.startswith('A:'):
                    question_data["options"]["A"] = line.replace('A:', '').strip()
                elif line.startswith('B:'):
                    question_data["options"]["B"] = line.replace('B:', '').strip()
                elif line.startswith('C:'):
                    question_data["options"]["C"] = line.replace('C:', '').strip()
                elif line.startswith('D:'):
                    question_data["options"]["D"] = line.replace('D:', '').strip()
                elif line.startswith('ANSWER:'):
                    question_data["correct_answer"] = line.replace('ANSWER:', '').strip()
                elif line.startswith('HINT:'):
                    question_data["hint"] = line.replace('HINT:', '').strip()
                elif line.startswith('EXPLANATION:'):
                    question_data["explanation"] = line.replace('EXPLANATION:', '').strip()
            
            return question_data
        except:
            return None
    
    def save_questions(self, questions_data, filename=None):
        """LÆ°u cÃ¢u há»i ra file"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"questions_{timestamp}.json"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(questions_data, f, indent=2, ensure_ascii=False)
            
            print(f"ğŸ’¾ ÄÃ£ lÆ°u cÃ¢u há»i vÃ o: {filename}")
            return filename
        except Exception as e:
            print(f"âŒ Lá»—i lÆ°u file: {str(e)}")
            return None
    
    def display_questions(self, questions_data):
        """Hiá»ƒn thá»‹ cÃ¢u há»i ra mÃ n hÃ¬nh"""
        print("\n" + "="*80)
        print("ğŸ“‹ CÃ‚U Há»I TRáº®C NGHIá»†M ÄÃƒ Táº O")
        print("="*80)
        
        for q in questions_data.get("questions", []):
            print(f"\nğŸ”¢ CÃ¢u {q.get('id', '?')}: {q.get('question', 'N/A')}")
            print("-" * 60)
            
            options = q.get('options', {})
            for key in ['A', 'B', 'C', 'D']:
                if key in options:
                    print(f"   {key}. {options[key]}")
            
            print(f"\nâœ… ÄÃ¡p Ã¡n Ä‘Ãºng: {q.get('correct_answer', 'N/A')}")
            print(f"ğŸ’¡ Gá»£i Ã½: {q.get('hint', 'KhÃ´ng cÃ³')}")
            print(f"ğŸ“ Giáº£i thÃ­ch: {q.get('explanation', 'KhÃ´ng cÃ³')}")
            print("-" * 60)
    
    def process_pdf(self, pdf_path, num_questions=5):
        """Quy trÃ¬nh hoÃ n chá»‰nh: PDF â†’ CÃ¢u há»i"""
        print(f"ğŸš€ Báº®T Äáº¦U Xá»¬ LÃ: {Path(pdf_path).name}")
        print("="*60)
        
        # BÆ°á»›c 1: Chuyá»ƒn PDF sang text
        if not self.convert_pdf_to_text(pdf_path):
            return None
        
        # BÆ°á»›c 2: Táº¡o embeddings Ä‘á»ƒ hiá»ƒu tÃ i liá»‡u
        if not self.create_embeddings():
            return None
        
        # BÆ°á»›c 3: Táº¡o cÃ¢u há»i
        questions_data = self.generate_questions(num_questions)
        
        if questions_data and questions_data.get("questions"):
            # BÆ°á»›c 4: Hiá»ƒn thá»‹ káº¿t quáº£
            self.display_questions(questions_data)
            
            # BÆ°á»›c 5: LÆ°u file
            filename = self.save_questions(questions_data)
            
            print(f"\nğŸ‰ HOÃ€N THÃ€NH!")
            print(f"ğŸ“Š ÄÃ£ táº¡o {len(questions_data['questions'])} cÃ¢u há»i")
            print(f"ğŸ’¾ File káº¿t quáº£: {filename}")
            
            return questions_data
        else:
            print("âŒ KhÃ´ng thá»ƒ táº¡o cÃ¢u há»i")
            return None

    def generate_questions_batch_optimized(self, num_questions=5):
        """Táº¡o cÃ¢u há»i vá»›i batch processing tá»‘i Æ°u cho tá»‘c Ä‘á»™"""
        print(f"ğŸš€ Táº¡o {num_questions} cÃ¢u há»i (OPTIMIZED)...")
        
        # Táº¡o tÃ³m táº¯t náº¿u chÆ°a cÃ³
        if not self.document_summary:
            self.generate_document_summary()
        
        # Tá»‘i Æ°u batch size dá»±a trÃªn sá»‘ cÃ¢u há»i
        if num_questions <= 10:
            batch_size = num_questions  # Táº¡o má»™t láº§n
        elif num_questions <= 50:
            batch_size = 10  # Batch 10 cÃ¢u
        else:
            batch_size = 15  # Batch 15 cÃ¢u cho sá»‘ lÆ°á»£ng lá»›n
        
        all_questions = []
        total_batches = (num_questions + batch_size - 1) // batch_size
        
        print(f"ğŸ“¦ Xá»­ lÃ½ {total_batches} batch (tá»‘i Ä‘a {batch_size} cÃ¢u/batch)")
        
        for batch_num in range(total_batches):
            start_idx = batch_num * batch_size
            end_idx = min(start_idx + batch_size, num_questions)
            questions_in_batch = end_idx - start_idx
            
            print(f"âš¡ Batch {batch_num + 1}/{total_batches}: {questions_in_batch} cÃ¢u")
            
            # Táº¡o prompt tá»‘i Æ°u cho batch
            prompt = self.create_optimized_batch_prompt(questions_in_batch, batch_num)
            
            try:
                # Gá»i API vá»›i timeout ngáº¯n hÆ¡n
                response = self.call_openai_api_optimized(prompt, max_tokens=3000)
                
                # Parse response
                batch_questions = self.parse_questions_response_fast(response)
                
                if batch_questions:
                    all_questions.extend(batch_questions)
                    print(f"âœ… Batch {batch_num + 1}: +{len(batch_questions)} cÃ¢u")
                else:
                    print(f"âš ï¸ Batch {batch_num + 1}: KhÃ´ng cÃ³ cÃ¢u há»i há»£p lá»‡")
                    
            except Exception as e:
                print(f"âŒ Lá»—i batch {batch_num + 1}: {str(e)}")
                continue
        
        print(f"ğŸ¯ HoÃ n thÃ nh: {len(all_questions)}/{num_questions} cÃ¢u há»i")
        return all_questions[:num_questions]  # Äáº£m báº£o khÃ´ng vÆ°á»£t quÃ¡ yÃªu cáº§u

    def create_optimized_batch_prompt(self, num_questions, batch_num):
        """Táº¡o prompt tá»‘i Æ°u cho batch processing"""
        # Láº¥y content relevant cho batch nÃ y
        relevant_content = self.get_diverse_content_for_batch(batch_num)
        
        prompt = f"""Dá»±a trÃªn ná»™i dung tÃ i liá»‡u sau, hÃ£y táº¡o CHÃNH XÃC {num_questions} cÃ¢u há»i tráº¯c nghiá»‡m cháº¥t lÆ°á»£ng cao.

Ná»˜I DUNG THAM KHáº¢O:
{self.document_summary}

CHI TIáº¾T:
{relevant_content}

YÃŠU Cáº¦U:
- Táº¡o ÄÃšNG {num_questions} cÃ¢u há»i (khÃ´ng Ã­t hÆ¡n, khÃ´ng nhiá»u hÆ¡n)
- Má»—i cÃ¢u há»i cÃ³ 4 lá»±a chá»n A, B, C, D
- ÄÃ¡p Ã¡n chÃ­nh xÃ¡c vÃ  giáº£i thÃ­ch rÃµ rÃ ng
- CÃ¢u há»i Ä‘a dáº¡ng vá» má»©c Ä‘á»™ (dá»…, trung bÃ¬nh, khÃ³)
- Táº­p trung vÃ o kiáº¿n thá»©c cá»‘t lÃµi

FORMAT JSON (QUAN TRá»ŒNG):
[
    {{
        "question": "CÃ¢u há»i 1...",
        "type": "multiple_choice",
        "hint": "Gá»£i Ã½...",
        "correct_answer": "A",
        "options": [
            {{"answer": "A", "reason": "ÄÃ¡p Ã¡n A vÃ¬..."}},
            {{"answer": "B", "reason": "ÄÃ¡p Ã¡n B sai vÃ¬..."}},
            {{"answer": "C", "reason": "ÄÃ¡p Ã¡n C sai vÃ¬..."}},
            {{"answer": "D", "reason": "ÄÃ¡p Ã¡n D sai vÃ¬..."}}
        ]
    }}
]

Chá»‰ tráº£ vá» JSON array, khÃ´ng giáº£i thÃ­ch thÃªm."""
        
        return prompt

    def get_diverse_content_for_batch(self, batch_num):
        """Láº¥y ná»™i dung Ä‘a dáº¡ng cho má»—i batch"""
        if not self.chunks:
            return ""
        
        # TÃ­nh offset Ä‘á»ƒ má»—i batch cÃ³ ná»™i dung khÃ¡c nhau
        chunks_per_batch = max(3, len(self.chunks) // 4)
        start_idx = (batch_num * chunks_per_batch) % len(self.chunks)
        
        # Láº¥y chunks vá»›i rotation Ä‘á»ƒ Ä‘áº£m báº£o Ä‘a dáº¡ng
        selected_chunks = []
        for i in range(chunks_per_batch):
            chunk_idx = (start_idx + i) % len(self.chunks)
            selected_chunks.append(self.chunks[chunk_idx])
        
        return "\n\n---\n\n".join(selected_chunks)

    def call_openai_api_optimized(self, prompt, max_tokens=3000):
        """Gá»i OpenAI API vá»›i tá»‘i Æ°u hÃ³a tá»‘c Ä‘á»™"""
        try:
            import requests
            import json
            
            headers = {
                'Content-Type': 'application/json',
                'Authorization': f'Bearer {self.openai_api_key}'
            }
            
            data = {
                'model': 'gpt-3.5-turbo',  # Sá»­ dá»¥ng model nhanh hÆ¡n
                'messages': [
                    {
                        'role': 'user',
                        'content': prompt
                    }
                ],
                'max_tokens': max_tokens,
                'temperature': 0.7,
                'timeout': 30  # Timeout ngáº¯n
            }
            
            response = requests.post(
                'https://api.openai.com/v1/chat/completions',
                headers=headers,
                json=data,
                timeout=30  # Request timeout
            )
            
            if response.status_code == 200:
                result = response.json()
                return result['choices'][0]['message']['content']
            else:
                print(f"âŒ OpenAI API error: {response.status_code}")
                print(f"Response: {response.text}")
                return None
                
        except requests.exceptions.Timeout:
            print("â° OpenAI API timeout")
            return None
        except Exception as e:
            print(f"âŒ Lá»—i gá»i OpenAI API: {str(e)}")
            return None

    def parse_questions_response_fast(self, response):
        """Parse response nhanh vá»›i error handling tá»‘t"""
        if not response:
            return []
        
        try:
            # TÃ¬m JSON trong response
            import re
            
            # TÃ¬m JSON array pattern
            json_pattern = r'\[[\s\S]*\]'
            json_match = re.search(json_pattern, response)
            
            if json_match:
                json_str = json_match.group(0)
                questions = json.loads(json_str)
                
                # Validate questions format
                valid_questions = []
                for q in questions:
                    if self.validate_question_format_fast(q):
                        valid_questions.append(q)
                
                return valid_questions
            else:
                # Fallback: tÃ¬m cÃ¡ch parse khÃ¡c
                return self.parse_questions_fallback(response)
                
        except json.JSONDecodeError as e:
            print(f"âš ï¸ Lá»—i parse JSON: {str(e)}")
            return self.parse_questions_fallback(response)
        except Exception as e:
            print(f"âš ï¸ Lá»—i parse response: {str(e)}")
            return []

    def validate_question_format_fast(self, question):
        """Validate format cÃ¢u há»i nhanh"""
        try:
            required_fields = ['question', 'type', 'hint', 'correct_answer', 'options']
            
            # Kiá»ƒm tra cÃ¡c field báº¯t buá»™c
            for field in required_fields:
                if field not in question:
                    return False
            
            # Kiá»ƒm tra options
            options = question.get('options', [])
            if len(options) != 4:
                return False
            
            # Kiá»ƒm tra format options
            for option in options:
                if not isinstance(option, dict):
                    return False
                if 'answer' not in option or 'reason' not in option:
                    return False
            
            return True
            
        except Exception:
            return False

    def parse_questions_fallback(self, response):
        """Fallback parsing cho trÆ°á»ng há»£p JSON khÃ´ng chuáº©n"""
        try:
            # Implement simple parsing logic
            questions = []
            # Add simple regex-based parsing if needed
            print("ğŸ”„ Sá»­ dá»¥ng fallback parsing...")
            return questions
        except Exception:
            return []
    
def main():
    """HÃ m chÃ­nh"""
    generator = PDFQuestionGenerator()
    
    # TÃ¬m file PDF
    pdf_files = list(Path(".").glob("*.pdf"))
    
    if pdf_files:
        print("ğŸ“‹ File PDF tÃ¬m tháº¥y:")
        for i, pdf_file in enumerate(pdf_files, 1):
            file_size = os.path.getsize(pdf_file) / 1024
            print(f"   {i}. {pdf_file.name} ({file_size:.1f} KB)")
        
        try:
            choice = input(f"\nğŸ”¢ Chá»n file (1-{len(pdf_files)}) hoáº·c nháº­p Ä‘Æ°á»ng dáº«n: ").strip()
            
            if choice.isdigit() and 1 <= int(choice) <= len(pdf_files):
                pdf_path = str(pdf_files[int(choice) - 1])
            else:
                pdf_path = choice.strip('"').strip("'")
                
        except (ValueError, KeyboardInterrupt):
            print("\nğŸ‘‹ ÄÃ£ há»§y!")
            return
    else:
        pdf_path = input("ğŸ“ Nháº­p Ä‘Æ°á»ng dáº«n Ä‘áº¿n file PDF: ").strip('"').strip("'")
    
    if not pdf_path or not os.path.exists(pdf_path):
        print("âŒ File PDF khÃ´ng tá»“n táº¡i!")
        return
    
    # Nháº­p sá»‘ cÃ¢u há»i
    try:
        num_questions = int(input("\nğŸ”¢ Sá»‘ cÃ¢u há»i muá»‘n táº¡o (máº·c Ä‘á»‹nh 5): ") or "5")
        if num_questions < 1:
            print("âš ï¸ Sá»‘ cÃ¢u há»i pháº£i lá»›n hÆ¡n 0, Ä‘áº·t vá» máº·c Ä‘á»‹nh")
            num_questions = 5
        elif num_questions > 200:
            print("âš ï¸ Sá»‘ cÃ¢u há»i quÃ¡ lá»›n, giá»›i háº¡n tá»‘i Ä‘a 200 cÃ¢u")
            num_questions = 200
    except ValueError:
        print("âš ï¸ Sá»‘ khÃ´ng há»£p lá»‡, sá»­ dá»¥ng máº·c Ä‘á»‹nh")
        num_questions = 5
    
    # Xá»­ lÃ½ PDF vÃ  táº¡o cÃ¢u há»i
    result = generator.process_pdf(pdf_path, num_questions)
    
    if result:
        print("\nâœ… QuÃ¡ trÃ¬nh hoÃ n táº¥t thÃ nh cÃ´ng!")
    else:
        print("\nâŒ QuÃ¡ trÃ¬nh tháº¥t báº¡i!")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ÄÃ£ dá»«ng bá»Ÿi ngÆ°á»i dÃ¹ng!")
    except Exception as e:
        print(f"\nâŒ Lá»—i nghiÃªm trá»ng: {str(e)}")
        sys.exit(1)